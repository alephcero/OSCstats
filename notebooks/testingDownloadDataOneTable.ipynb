{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString\n",
    "import shapely.wkt\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import loadOSCdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def downloadData(textfile, X = True, Y = True, Z = True, output = 'csv', outputFile = 'data.csv'):\n",
    "    '''\n",
    "    This function takes a text file from OSC in the phone\n",
    "    The axis we want to consider to compute the final vector (X, Y, Z)\n",
    "    And the output formats and file\n",
    "    and returns a dataframe with the V values for each gps coordinate point\n",
    "    '''\n",
    "    #read original data from file within track.txt.gz used by OSC to store sensor data\n",
    "    data = pd.read_csv(textfile,sep=';',\n",
    "                   skiprows=[0],\n",
    "                   skipfooter=1,\n",
    "                   usecols=[0,1,2,9,10,11,15],\n",
    "                   header=None,\n",
    "                   engine = 'python')\n",
    "\n",
    "    #naming of columns \n",
    "    data.columns = ['timestamp','long','lat','accelerationX','accelerationY','accelerationZ','photoIndex'] \n",
    "    \n",
    "    #conversion into timestamp\n",
    "    #dates = []\n",
    "    #for i in range(data.shape[0]):\n",
    "    #    try:\n",
    "    #        dates.append(datetime.datetime.fromtimestamp(data['timestamp'].iloc[i]))\n",
    "    #    except :\n",
    "    #        print 'Error with row:', i\n",
    "    #data['timestamp'] = dates        \n",
    "    \n",
    "    #remove all empty rows except timestamp\n",
    "    emtpy = data.iloc[:,1:].isnull().sum(axis=1) == data.shape[1]-1\n",
    "    data = data.loc[~emtpy,:]\n",
    "    data.index=range(data.shape[0])\n",
    "    \n",
    "\n",
    "    data.dropna(axis=0,how='all',\n",
    "                subset = ['long','lat','accelerationX','accelerationY','accelerationZ','photoIndex'],\n",
    "                inplace=True)\n",
    "    \n",
    "    \n",
    "    #CREATE A PHOTOS DATAFRAME\n",
    "    dataPhotos = data.loc[~data.photoIndex.isnull(),['timestamp','photoIndex']]\n",
    "    data.drop(['photoIndex'],axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    #'''\n",
    "    #create the geography\n",
    "    gpsDataPoints =  data.loc[~ (data['long'].isnull()),['timestamp','long','lat']]\n",
    "    gpsDataPoints['pointIndex'] = gpsDataPoints.index\n",
    "    \n",
    "    geometry = []\n",
    "    for i in range(len(gpsDataPoints.index)):\n",
    "        if i == (len(gpsDataPoints.index)-1):\n",
    "            line = np.nan\n",
    "        else:\n",
    "            #get start and end points for each line\n",
    "            startPoint = Point(gpsDataPoints['long'].loc[gpsDataPoints.index[i]], gpsDataPoints['lat'].loc[gpsDataPoints.index[i]])\n",
    "            endPoint = Point(gpsDataPoints['long'].loc[gpsDataPoints.index[i+1]], gpsDataPoints['lat'].loc[gpsDataPoints.index[i+1]])\n",
    "            #convert to shapely wkt\n",
    "            line = LineString([startPoint,endPoint]).wkt\n",
    "            geometry.append(shapely.wkt.loads(line).centroid)\n",
    "    \n",
    "    gpsDataPoints = gpsDataPoints.iloc[:-1]\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    gpsDataPoints = gpd.GeoDataFrame(gpsDataPoints, crs=crs, geometry=geometry)\n",
    "    \n",
    "    #Asign to data the index of the points with GPS data\n",
    "    data.drop(['timestamp'],axis=1,inplace=True)\n",
    "    data = data.merge(gpsDataPoints.drop(['timestamp','geometry'],axis=1),how='left')\n",
    "    data['pointIndex'] = data['pointIndex'].fillna(method='ffill')\n",
    "    \n",
    "    #shift data lag 1 to take the vector of the difference in axis XYZ\n",
    "    dataShifted = data.shift(1)\n",
    "    dataShifted.drop(['long','lat','pointIndex'],axis=1,inplace=True)\n",
    "    dataShifted.columns = ['accelerationXShift','accelerationYShift','accelerationZShift']\n",
    "    \n",
    "    #concatenate datasets\n",
    "    data = pd.concat([data,dataShifted],axis=1)\n",
    "    data.drop(['long','lat'],axis=1,inplace=True)\n",
    "    data.dropna(axis=0,how='any',inplace=True)\n",
    "    \n",
    "    #compute vector\n",
    "    \n",
    "    data['V'] = np.sqrt((data.accelerationX-data.accelerationXShift) ** 2 * X + \\\n",
    "    (data.accelerationY-data.accelerationYShift) ** 2 * Y + \\\n",
    "    (data.accelerationZ-data.accelerationZShift) ** 2 * Z) \n",
    "    \n",
    "    #get the sum of every lag BY line defined by the starting point (with GPS data)\n",
    "    vectorInformation = data.loc[:,['pointIndex','V']].groupby(by=['pointIndex']).sum()\n",
    "    vectorInformation.reset_index(inplace=True)\n",
    "    gpsDataPoints = gpsDataPoints.merge(vectorInformation)\n",
    "    \n",
    "    #gpsDataPoints.timestamp = gpsDataPoints.timestamp.map(lambda x: str(x))\n",
    "    \n",
    "    photoPoints = []\n",
    "    photoV = []\n",
    "\n",
    "    for i in range(dataPhotos.shape[0]):\n",
    "        if i == (dataPhotos.shape[0]-1):\n",
    "            break\n",
    "        else:\n",
    "            dataAggregated = gpsDataPoints.loc[(gpsDataPoints.timestamp > dataPhotos.timestamp.iloc[i]) & (gpsDataPoints.timestamp < dataPhotos.timestamp.iloc[i+1]),:]\n",
    "            photoV.append(dataAggregated.V.sum())\n",
    "            photoPoints.append(dataAggregated.geometry.iloc[0])\n",
    "    dataPhotos = dataPhotos.iloc[:dataPhotos.shape[0]-1,:]        \n",
    "    dataPhotos['V'] = photoV\n",
    "    dataPhotos['geometry'] = photoPoints\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    dataPhotos = gpd.GeoDataFrame(dataPhotos, crs=crs, geometry=dataPhotos.geometry)\n",
    "    \n",
    "    if output == 'csv':\n",
    "        gpsDataPoints.to_csv(outputFile)\n",
    "    elif output == 'shp':\n",
    "        gpsDataPoints.to_file(outputFile)\n",
    "    else:\n",
    "        raise NameError('You can only export to csv or shp files')\n",
    "    \n",
    "    #return gpsDataPoints\n",
    "    #'''\n",
    "    return (gpsDataPoints,dataPhotos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = True\n",
    "Y = True\n",
    "Z = True\n",
    "output = 'csv'\n",
    "outputFile = 'data.csv'\n",
    "dataType = 'accelerometer'\n",
    "OSCid=464547\n",
    "diccion = loadOSCdata.getOSCjson(OSCid)\n",
    "diccion = diccion['osv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url='http://openstreetcam.org/'+diccion['meta_data_filename']\n",
    "url          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the accelerometer data with loadOSCdata function\n",
    "#tupla = downloadData('/home/pipe/Dropbox/NYU/classes/Capstone/OSCstats/track.txt', X = X, Y = Y, Z = Z, output = output, outputFile = outputFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tupla = downloadData(url, X = X, Y = Y, Z = Z, output = output, outputFile = outputFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = tupla[0]\n",
    "dataPhotos = tupla[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataPhotos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diccion['photos'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diccion['photos'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fotos = loadOSCdata.queryOSCapi(OSCid = 464547, output = 'shp', outputFile = 'photos',dataType='photos')\n",
    "fotos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curl 'https://southcentralus.api.cognitive.microsoft.com/customvision/v1.0/Prediction/16d2699a-3afd-4548-a7d3-2263abf5be63/url?iterationId=d6c29a8a-8001-49eb-b497-9f8b7109dfe7&application=quicktest' -H 'Origin: https://customvision.ai' -H 'Accept-Encoding: gzip, deflate, br' -H 'Accept-Language: en-US,en;q=0.8,es;q=0.6' -H 'Prediction-Key: a6886e6f5b834133880fcde81d496cdd' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36' -H 'Content-Type: application/json;charset=UTF-8' -H 'Training-Key: 4fb7652c838747da9989682b2d382150' -H 'Accept: application/json, text/plain, */*' -H 'Referer: https://customvision.ai/projects/16d2699a-3afd-4548-a7d3-2263abf5be63' -H 'Connection: keep-alive' -H 'DNT: 1' --data-binary '{\"Url\":\"http://storage4.openstreetcam.org/files/photo/2017/6/3/proc/441358_ff07a_5932edaa9492a.jpg\"}' --compressed"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
